environment_config:
  n_agents: 10
  n_dim: 2
  ep_length: 50
  freeze: True
  fraq_refinement: 0.5
  # env_list: [minmax, cosine_mixture, ghabit, cos_function]
  env_list: [cosine_mixture,cos_function, minmax, ghabit]
  # bounds: [[(-3, -3),(3, 3)], [(-1, -1),(1, 1)], [(-3, -3), (3, 3)], [(-10, -10), (-3, -3)]]
  bounds: [[(-1, -1),(1, 1)], [(-3, -3), (3, 3)], [(-3, -3), (3, 3)], ]
  max_episodes: 2001
  plot_directory: plots/
  gif_directory: gifs/
  fps: 0.8
  env_ids: [0, 1, 2, 3]
  change_freq: 5
  use_actual_best: True
  envs_cache_path: environment_cache/
  envs_cache_file: opt_env_cache.pickle
  reward_log_freq: 10
  reward_type: full
  opt_bound: 0.9
  split_agent: False

policy_config:
  state_dim: 4
  action_dim: 1
  init_std: 0.3
  std_min: 0.05
  std_max: 0.3
  std_type: 'linear_decay'
  fixed_std: True
  std_pow: 1
  std_switch_time: 4000
  hidden_dim: [32, 32]
  lr: 0.00001
  betas: 0.999
  gamma: 0.9
  K_epochs: 32
  eps_clip: 0.2
  initialization: None
  pretrained: False
  learn_std: False
  activation: None
  ckpt_path: None
  split_fraq: 0.5
  std_decay_rate: 0.001
  ckpt_folder: logs/pbest_exp_2/checkpoints/policy_v2_ep_2000.pth
  std_mode: hybrid
  split_agent: True

train_config:
  save_interval: 500
  update_interval: 50
  model_path: 'models/'
  gif_path: 'gifs/'
  save_cutoff: 100
  render_interval: 500
  print_interval: 1000
  transition_time: 5000
  decay_interval: 100
  mode: train
  log_interval: 500
  plot_flag: True
  use_gbest: False
  
  
test_config:
  n_agents: 10
  n_dim: 2
  ep_length: 25
  freeze: True
  fraq_refinement: 0.5
  n_run: 10
  plot_directory: plots/
  gif_directory: gifs/
  fps: 0.8
  env_ids: [0, 1, 2, 3]
  change_freq: 5
  use_actual_best: True
  envs_cache_path: environment_cache/
  envs_cache_file: opt_env_cache.pickle
  reward_log_freq: 10
  reward_type: full
  opt_bound: 0.9
  init_std: 0.4
  std_min: 0.02
  std_max: 0.2
  std_type: 'euclidean'
  fixed_std: True
  std_decay_rate: 0.02
  learn_std: True
  std_mode: hybrid
  ckpt_folder: logs/nosplit_model.pth
  state_dim: 4
  action_dim: 1
  hidden_dim: [32, 32]
  pretrained: True
  use_gbest: False
  std_type: linear_decay
